---
title: "ASUbuildR"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: scroll
runtime: shiny
editor_options: 
  markdown: 
    wrap: 72
---
```{r python_preamble, include=FALSE}
library(reticulate)
library(processx)

# Check if Python environment is set up, prompt user if not
venv_path <- file.path(rappdirs::user_data_dir("ASUbuildR"), "asu-cpsat-venv")

python_ready <- FALSE

# Check if virtual environment exists
if (dir.exists(venv_path)) {
  # Try to use it
  tryCatch({
    reticulate::use_virtualenv(venv_path, required = TRUE)
    
    # Check if packages are available
    if (reticulate::py_module_available("ortools")) {
      python_ready <- TRUE
      message("[env] Python environment ready")
    } else {
      message("[env] Python packages not fully installed")
    }
  }, error = function(e) {
    message("[env] Virtual environment exists but cannot be activated")
  })
} else {
  message("[env] Python environment not set up")
  message("[env] Users should run ASUbuildR::setup_asu_python() before using CP-SAT solver")
}

# Store the status for later use
options(asu_python_ready = python_ready)
```

```{r setup, include=FALSE}
# Figure out full paths to src/ C++ files, going up two levels
src_cpp_files <- c("choose_best_neighbor.cpp",
                   "build_edges.cpp",
                   "choose_best_drop.cpp")

src_paths <- normalizePath(file.path("..", "..", "src", src_cpp_files),
                           winslash = "/", mustWork = FALSE)

# Check that all source files are there
in_repo <- all(file.exists(src_paths))

maybe_sourceCpp <- function(fun, path) {
  if (!exists(fun, mode = "function") && file.exists(path)) {
    message("Compiling ", basename(path))
    Rcpp::sourceCpp(path)
  }
}

if (in_repo) {
  message("→ Dev mode: compiling C++ helpers from src/")
  maybe_sourceCpp("choose_best_neighbor", src_paths[1])
  maybe_sourceCpp("build_edges",          src_paths[2])
  maybe_sourceCpp("choose_best_drop",     src_paths[3])
} else {
  message("→ Installed package mode (shared library already loaded)")

}

# ---- dev mode: source helper functions relative to this file ----------
is_dev_mode <- file.exists("../../DESCRIPTION") && dir.exists("../../R")

if (is_dev_mode) {
  message("→ Dev mode: sourcing from ../../R/")
  r_dir <- normalizePath("../../R", winslash = "/", mustWork = TRUE)

  source(file.path(r_dir, "run_tract_hunter.R"))
  source(file.path(r_dir, "run_asu_original.r"))
  source(file.path(r_dir,"setup_asu_python.R"))
} else {
  message("→ Installed package mode: functions should already be available")
}

`%||%` <- function(a, b) if (!is.null(a) && length(a)) a else b


# ── Use virtual environment & import Python module ───────────────────


# Use the virtual environment we set up in the preamble
venv_path <- file.path(rappdirs::user_data_dir("ASUbuildR"), "asu-cpsat-venv")
reticulate::use_virtualenv(venv_path, required = TRUE)
py_config()  # should now show the venv python

# Import your solver module from the package's inst/python
asu_py <- import_from_path(
  module  = "asu_cpsat",
  path    = normalizePath("../../inst/python", winslash = "/", mustWork = FALSE),
  convert = TRUE
)
stopifnot(py_has_attr(asu_py, "build_many_asus_cpsat"))


## ---- tigris cache ----------------------------------------------------
## put cached TIGER/Line ZIPs in a per-user cache folder that is always
## writable, even after the package is installed read-only.

# 1. choose a sensible user-cache path (rappdirs works everywhere)
cache_dir <- rappdirs::user_cache_dir("ASUbuildR", "tigris")

# 2. create it if it doesn't exist
if (!dir.exists(cache_dir))
  dir.create(cache_dir, recursive = TRUE, showWarnings = FALSE)

# 3. tell tigris to use it *this session*
options(tigris_cache_dir = cache_dir)

# tell tigris to look there first before re‑downloading
options(tigris_use_cache = TRUE)


# cache every tigris download automatically
options(
  tigris_use_cache = TRUE,                 # turn caching on
  tigris_class     = "sf"                  # always return sf objects
)

options(shiny.maxRequestSize = 50 * 1024^2)  # Set to 50MB or your desired limit

# Initialize reactive values
uploaded_data <- shiny::reactiveVal(NULL)
state <- shiny::reactiveVal(NULL)
tract_year <- shiny::reactiveVal(NULL)
tract_data <- shiny::reactiveVal(NULL)
asu_data <- shiny::reactiveVal(NULL)
asu_tracts <- shiny::reactiveVal(NULL)
asu_summary <- shiny::reactiveVal(NULL)
full_data <- shiny::reactiveVal(NULL)
full_data_reset <- shiny::reactiveVal()
selected_tracts <- shiny::reactiveVal(NULL)
edit_table <- shiny::reactiveVal(NULL)
edit_summary <- shiny::reactiveVal(NULL)
current_selection <- shiny::reactiveVal(NULL)
map_geom        <- shiny::reactiveVal(NULL)
# New England Optional year selection logic
output$is_new_england <- shiny::reactive({
  if (is.null(state())) {
    return(FALSE)
  }

  # New England state FIPS codes
  new_england_fips <- c("09", "23", "25", "33", "44", "50") # CT, ME, MA, NH, RI, VT

  state() %in% new_england_fips
})

# ---- CP-SAT logging + paths ----
cpsat_log_buf    <- shiny::reactiveVal("")
cpsat_solver_proc<- shiny::reactiveVal(NULL)
cpsat_run_dir    <- shiny::reactiveVal(NULL)
cpsat_df_csv     <- shiny::reactiveVal(NULL)
cpsat_nb_json    <- shiny::reactiveVal(NULL)
cpsat_out_json   <- shiny::reactiveVal(NULL)
cpsat_log_file   <- shiny::reactiveVal(NULL)

append_cpsat_log <- function(...) {
  line <- paste0(format(Sys.time(), "%H:%M:%S "), paste0(..., collapse = ""))
  old  <- cpsat_log_buf()
  new  <- if (nzchar(old)) paste(old, line, sep = "\n") else line
  if (nchar(new) > 12000) new <- substr(new, nchar(new) - 11999, nchar(new))
  cpsat_log_buf(new)
  output$cpsat_log_tail <- shiny::renderText(new)
}

# keep log output live even if hidden
output$cpsat_log_tail <- shiny::renderText("")
shiny::outputOptions(output, "cpsat_log_tail", suspendWhenHidden = FALSE)
# ---- New England year override logic ---------------------------------
# Make it available to the UI
shiny::outputOptions(output, "is_new_england", suspendWhenHidden = FALSE)

# Tract Hunter staged state -----------------------------------------
th_state <- shiny::reactiveVal(NULL)
th_tract_list <- shiny::reactiveVal(NULL)
th_bls_df <- shiny::reactiveVal(NULL)
prep_map_data <- function(map_data) {
  map_data |>
    sf::st_make_valid() |>
    sf::st_zm(what = "ZM", drop = TRUE) |>
    dplyr::filter(!sf::st_is_empty(geometry)) |>
    dplyr::mutate(geom_type = sf::st_geometry_type(geometry)) |>
    dplyr::filter(geom_type %in% c("POLYGON", "MULTIPOLYGON")) |>
    dplyr::select(-geom_type)
}
map_geom <- shiny::reactiveVal(NULL)

highlighted_tracts <- shiny::reactiveVal(character(0))

# Load static data
excel_names <- c("record",
                 "geoid",
                 "st_fips",
                 "cnty_fips",
                 "tract_fips",
                 "name",
                 "tract_pop_dec",
                 "tract_pop_cur",
                 "tract_emp",
                 "tract_unemp",
                 "tract_urate",
                 "tract_urate_error",
                 "cnty_pop_dec",
                 "cnty_pop_cur",
                 "cnty_emp",
                 "cnty_unemp",
                 "cnty_urate",
                 "cnty_urate_error",
                 "pop_shr",
                 "emp_shr",
                 "unemp_shr",
                 "laus_primary",
                 "cnty_emp_ave",
                 "cnty_unemp_ave",
                 "tract_ASU_clf",
                 "tract_ASU_emp",
                 "tract_ASU_unemp",
                 "tract_ASU_urate")
```

# Data Initialization

## Controls {data-width="150"}

This screen allows you to import the BLS-provided ASU file, generally named like *NV_asu23.xlsx* which will be the only external data import step necessary. The script will read the file, extract the state and corresponding year, and standardize the column names to avoid annual updates to the script.

If the necessary data is not in columns **A through AB** within the Excel file, this process will not work correctly.

Once the file is loaded, a preview of the data will appear on the right, the state and year will display below, and the analyst may proceed to the next tab (Load Initial ASU).

Note: at this time, ASUbuildR assumes a state is using county-based census tracts.  If a state uses another geography such as NECTAs as the basis for its ASU tract file, this process will require some modification.

```{r}
shiny::fileInput("file", "Choose Excel File", accept = c(".xls", ".xlsx"))

shiny::textOutput("selected_state")

shiny::textOutput("selected_year")
```

## Output {data-width="850"}

```{r}
shiny::tableOutput("data_preview")

shiny::observeEvent(input$file, {
  shiny::req(input$file)
  df <- readxl::read_excel(input$file$datapath, range = "A2:AB25000", col_names = excel_names) |>
    dplyr::filter(!is.na(geoid)) |>
    dplyr::mutate(GEOID = stringr::str_remove(geoid, "14000US")) |>
    dplyr::select(GEOID,
           st_fips,
           cnty_fips,
           tract_fips,
           name,
           tract_pop_cur,
           tract_ASU_clf,
           tract_ASU_emp,
           tract_ASU_unemp,
           tract_ASU_urate) |> 
    dplyr::mutate(
      tract_pop_cur = as.integer(tract_pop_cur),
      tract_ASU_clf = as.integer(tract_ASU_clf),
      tract_ASU_emp = as.integer(tract_ASU_emp),
      tract_ASU_unemp = as.integer(tract_ASU_unemp)
    )
  
  uploaded_data(df)
  
  uploaded_data() |>
    dplyr::pull(st_fips) |>
    unique() |>
    state()
  
  readxl::read_excel(input$file$datapath, range = "H1:H1", col_names = "year") |>
    dplyr::pull(year) |>
    stringr::str_remove("tract_pop") |>
    tract_year()
  
  output$data_preview <- shiny::renderTable({
    head(uploaded_data(),50)
  })
  
  output$selected_state <- shiny::renderText({
    paste0("Selected FIPS is: ", state())
  })
  
  output$selected_year <- shiny::renderText({
    paste0("Tract Population Year is: ", tract_year())
  })
})
```

# Load Initial ASU

## Controls {data-width="200"}

```{r}
# ---- New England year override controls ------------------------------
shiny::conditionalPanel(
  condition = "output.is_new_england === true",
  shiny::tagList(
    shiny::hr(style = "margin: 0.8rem 0;"),
    shiny::h5("New England Year Selection"),
    shiny::radioButtons(
      inputId = "ne_year_choice",
      label   = "Choose tract year:",
      choices = list(
        "Use detected year (default)" = "detected",
        "Use 2021 (last NECTA year)"  = "2021"
      ),
      selected = "detected",
      inline = FALSE
    ),
    shiny::p(
      style = "font-size: 0.9em; color: #666;",
      "Note: 2021 is the last year NECTA-based tracts were available for New England states."
    )
  )
)

# ---- algorithm picker -------------------------------------------------
shiny::radioButtons(
  inputId = "asu_algo",
  label   = "Choose algorithm",
  choices = c(
    "Tract Hunter"      = "mine",
    "Simple Snake"      = "orig",
    "CP-SAT (OR-Tools)" = "cpsat"
  ),
  inline  = TRUE
)


# -----------------------------------------------------------------------
# main "Run" button (always visible)
shiny::div(style = "margin-top: 0.5rem;",
    shiny::actionButton(
      inputId = "process",
      label   = "Load tracts & initialise",
      class   = "btn-primary"
    )
)

# -----------------------------------------------------------------------
# extra Tract-Hunter controls (only when algo == 'mine')
shiny::conditionalPanel(
  condition = "input.asu_algo === 'mine'",
  shiny::tagList(
    shiny::hr(style = "margin: 0.8rem 0;"),
    shiny::div(
      class = "btn-group",           # keep them on one line
      style = "width: 100%;",
      shiny::actionButton("th_pass",    "Run Hunter",     class = "btn-secondary"),
      shiny::actionButton("th_combine", "Combine Groups",   class = "btn-secondary")
    )
  )
)

# Conditional panel for CP-SAT algorithm options
shiny::conditionalPanel(
  condition = "input.asu_algo === 'cpsat'",
  shiny::tagList(
    shiny::hr(style = "margin: 0.8rem 0;"),
    shiny::numericInput("cpsat_tau",       "UR threshold (τ)",          value = 0.0645, min = 0, max = 1, step = 0.0001),
    shiny::numericInput("cpsat_pop",       "Population threshold",      value = 10000,  min = 0, step = 100),
    shiny::numericInput("cpsat_max",       "Max ASUs",                  value = 30,     min = 1, step = 1),
    shiny::numericInput("cpsat_timelimit", "Time limit (sec) per window", value = 1200, min = 1, step = 10),
    shiny::numericInput("cpsat_workers",   "Parallel workers",          value = max(1, parallel::detectCores()-5), min = 1, step = 1),
    shiny::numericInput("cpsat_relgap",    "Relative gap (optional)",   value = NA,     min = 0, step = 0.0001)
  )
)



# ---- dynamic algorithm description -----------------------------------
output$algo_blurb <- shiny::renderUI({

  if (is.null(input$asu_algo) || input$asu_algo == "orig") {
    ## ───────── ORIGINAL METHOD ─────────
    shiny::HTML(
      "<p>
        This button will launch two processes, which will take up to 5&nbsp;minutes
        to complete. For smaller states, it may take under 15&nbsp;seconds.
      </p>
      <p>
        First, the application will download census shapefiles by tract for the
        appropriate state and year. Next, after combining the BLS file with these
        shapefiles, it will iteratively search for contiguous geographic regions
        until the combined unemployment rate in each region is as close to
        6.45 % as possible.
      </p>
      <p>
        When this process is complete, a map will appear to the right, and a
        summary of the created ASU regions will appear below. It is important to
        note these will still include areas that do not qualify as an independent
        ASU (there is no check for population), but it gives the analyst a
        starting place for analysis.
      </p>
      <p>
        Once this step is done, you may proceed to the next step.
      </p>"
    )

  } else {
    ## ───────── TRACT-HUNTER METHOD ─────────
    shiny::HTML(
      "<p><strong>Tract Hunter workflow</strong></p>
       <p>Because Tract Hunter works in stages, the interface exposes those
          stages as separate buttons:</p>
       <ul>
         <li><em>Load tracts & initialise</em><br>
             ▸ downloads shapefiles, merges the BLS file, then runs the
             <strong>Seed + Expand</strong> step automatically. This should only be run once.</li>
         <li><em>Run Hunter</em><br>
             ▸ performs the optimisation/trade pass that adds
             high-unemployment neighbours and drops low-unemployment ones until
             every ASU is as close as possible to the
             <code>6.45%</code> threshold.</li>
         <li><em>Combine Groups</em><br>
             ▸ merges adjacent ASUs that share a boundary. Connected ASUs allow for more tracts to be added, so whenever ASUs are merged it is advisable to run another pass with the Tract Hunter.</li>
       </ul>
       <p>You can stop after any step to inspect the map, or run the buttons
          in sequence for the full, automatic workflow. We suggest iteratively running the Run Hunter and Combine Groups steps until Total Unemployment in ASUs no longer increases.  Each step updates the
          colour map and the unemployment totals shown on the right.</p>"
    )
  }
})

shiny::uiOutput("algo_blurb")

shiny::htmlOutput("total_unemp")

shiny::tableOutput("asu")
#shiny::verbatimTextOutput("cpsat_log_tail")

palette_logic <- function(n_asu) {
        if (n_asu == 0) {
          list(
            fill = "#808080",
            legend_vals = "(none)",
            legend_cols = "#808080"
          )
        } else if (n_asu == 1) {
          list(
            fill = mapgl::step_expr(
              column = "asunum",
              base = "#808080",
              stops = "#7FC97F",
              values = 1,
              na_color = "#444444"
            ),
            legend_vals = 1,
            legend_cols = "#7FC97F"
          )
        } else {
          pal <- RColorBrewer::brewer.pal(min(max(n_asu, 3L), 8L), "Accent")
          legend_vals <- seq_len(n_asu)
          legend_cols <- rep_len(pal, n_asu)

          list(
            fill = mapgl::match_expr(
              column = "asunum",
              values = legend_vals,
              stops = legend_cols
            ),
            legend_vals = legend_vals,
            legend_cols = legend_cols
          )
        }
      }
  # ---- end observeEvent -------------------------------------------------

shiny::observeEvent(input$process, {
  ## 0) Basic checks ------------------------------------------------------
  shiny::req(uploaded_data(), state(), tract_year())

  # Determine year (NE override)
  selected_year <- tract_year()
  state_val <- state()
  if (!is.null(state_val) && length(state_val) > 0) {
    new_england_fips <- c("09","23","25","33","44","50")
    if (state_val %in% new_england_fips &&
        !is.null(input$ne_year_choice) &&
        input$ne_year_choice == "2021") {
      selected_year <- "2021"
    }
  }

  shiny::withProgress(message = "Running OR-Tools CP-SAT…", value = 0, {
  append_cpsat_log("[run] Button clicked (CP-SAT).")

  # ---- 1) Preconditions & parameters ----------------------------------
  shiny::req(uploaded_data(), state(), tract_year())
  sel_year <- tract_year()
  st_fips  <- state()

  # New England year override (same logic you already use)
  ne_fips <- c("09","23","25","33","44","50")
  if (st_fips %in% ne_fips && !is.null(input$ne_year_choice) && input$ne_year_choice == "2021") {
    sel_year <- "2021"
  }

  tau      <- if (is.null(input$cpsat_tau))       0.0645 else as.numeric(input$cpsat_tau)
  pop_thr  <- if (is.null(input$cpsat_pop))       10000  else as.integer(input$cpsat_pop)
  max_asus <- if (is.null(input$cpsat_max))       30     else as.integer(input$cpsat_max)
  tlimit   <- if (is.null(input$cpsat_timelimit)) 1200   else as.integer(input$cpsat_timelimit)
  workers  <- if (is.null(input$cpsat_workers))   max(1L, parallel::detectCores()-5L) else as.integer(input$cpsat_workers)
  rel_gap  <- if (!is.null(input$cpsat_relgap) && !is.na(input$cpsat_relgap)) as.numeric(input$cpsat_relgap) else NA_real_

  append_cpsat_log(sprintf("[run] params: tau=%.6f pop=%d max=%d tlimit=%d workers=%d rel_gap=%s",
                           tau, pop_thr, max_asus, tlimit, workers,
                           if (is.na(rel_gap)) "None" else as.character(rel_gap)))

  # ---- 2) Build tracts + neighbors ------------------------------------
  shiny::incProgress(0.15, detail = "Downloading tracts & building neighbors")
  append_cpsat_log(sprintf("[NB] Downloading TIGER tracts for state %s (year=%s)…", st_fips, sel_year))

  tr_sf <- tigris::tracts(state = st_fips, year = sel_year, progress_bar = FALSE) |>
    dplyr::mutate(continuous = sfdep::st_contiguity(geometry))

  # join with uploaded BLS
  cols_needed <- c("GEOID","tract_ASU_unemp","tract_ASU_emp","tract_pop_cur","tract_ASU_clf","tract_ASU_urate")
  miss <- setdiff(cols_needed, names(uploaded_data()))
  if (length(miss)) {
    shiny::showModal(shiny::modalDialog(
      title="Input problem", paste("Uploaded data missing:", paste(miss, collapse=", ")), easyClose=TRUE
    ))
    return(invisible(NULL))
  }

  merged_sf <- tr_sf |>
    dplyr::left_join(uploaded_data(), by="GEOID")

  merged_df <- merged_sf |> sf::st_drop_geometry()
  append_cpsat_log(sprintf("[NB] Tracts kept: %d (after join)", nrow(merged_df)))

  # dataframe for Python
  df_py <- merged_df |>
    dplyr::transmute(
      geoid           = GEOID,
      tract_ASU_unemp = as.integer(tract_ASU_unemp),
      tract_ASU_emp   = as.integer(tract_ASU_emp),
      tract_pop2024   = as.integer(tract_pop_cur)
    )

  if (anyNA(df_py$tract_ASU_unemp) || anyNA(df_py$tract_ASU_emp) || anyNA(df_py$tract_pop2024)) {
    shiny::showModal(shiny::modalDialog(
      title="Input problem",
      "NA found after integer coercion (unemp/emp/pop). Fix the input file.",
      easyClose=TRUE
    ))
    return(invisible(NULL))
  }

  # 0-based neighbor lists
  nb_lists <- lapply(merged_sf$continuous, function(iv) {
    if (length(iv) == 0) list() else as.list(as.integer(iv) - 1L)
  })

  # ---- 3) Temp run folder + files --------------------------------------
  shiny::incProgress(0.10, detail = "Writing inputs")
  run_dir <- file.path(tempdir(), paste0("cpsat_", format(Sys.time(), "%Y%m%d_%H%M%S")))
  dir.create(run_dir, recursive = TRUE, showWarnings = FALSE)

  df_csv   <- file.path(run_dir, "df.csv")
  nb_json  <- file.path(run_dir, "nb.json")
  out_json <- file.path(run_dir, "out.json")
  runner   <- file.path(run_dir, "runner.py")

  utils::write.csv(df_py, df_csv, row.names = FALSE)
  jsonlite::write_json(nb_lists, nb_json, auto_unbox = TRUE)

  cpsat_run_dir(run_dir)
  cpsat_df_csv(df_csv)
  cpsat_nb_json(nb_json)
  cpsat_out_json(out_json)
  cpsat_log_file(NULL)         # we’ll stream stdout/stderr; no file needed

  append_cpsat_log(paste0("[run] Folder: ", run_dir))
  append_cpsat_log(paste0("[run] df.csv: ", df_csv))
  append_cpsat_log(paste0("[run] nb.json: ", nb_json))

  # ---- 4) Write runner.py (calls your Python module) -------------------
  shiny::incProgress(0.05, detail = "Preparing Python runner")
  py_mod_path <- normalizePath(file.path("..","..","inst","python"), winslash="/", mustWork = TRUE)
  runner_code <- sprintf("
import sys, os, json, math, traceback
try:
    sys.stdout.reconfigure(line_buffering=True)
except Exception:
    pass
os.environ.setdefault('PYTHONUNBUFFERED','1')
os.environ.setdefault('OMP_NUM_THREADS','1')
os.environ.setdefault('MKL_NUM_THREADS','1')
os.environ.setdefault('OPENBLAS_NUM_THREADS','1')
print('[runner] starting'); print('Python:', sys.version.replace('\\n',' '))

sys.path.insert(0, r'%s')
print('[runner] module path added')

from asu_cpsat import build_many_asus_cpsat
import pandas as pd

df = pd.read_csv(r'%s')
with open(r'%s','r') as f:
    nb = json.load(f)
print(f'[runner] inputs: rows={len(df)} nb_lists={len(nb)}')

kwargs = dict(
    df=df, nb=nb,
    tau=%s, pop_thresh=%d, max_asus=%d,
    time_limit=%d, workers=%d, verbose=True
)
REL = %s
if REL is not None and not (isinstance(REL, float) and math.isnan(REL)):
    kwargs['rel_gap'] = REL
print('[runner] launching CP-SAT…', flush=True)
res = build_many_asus_cpsat(**kwargs)
print('[runner] solver finished; writing json', flush=True)

# Support both dict and object with attribute
asu_id = res['asu_id'] if isinstance(res, dict) else getattr(res,'asu_id')
asu_id = [int(x) for x in asu_id]
with open(r'%s','w') as g:
    json.dump({'asu_id': asu_id}, g)
print('[runner] OK', flush=True)
",
    py_mod_path, df_csv, nb_json,
    format(tau, scientific = FALSE), pop_thr, max_asus, tlimit, workers,
    if (is.na(rel_gap)) "None" else as.character(rel_gap),
    out_json
  )
  writeLines(runner_code, runner)
  append_cpsat_log(paste0("[run] runner.py: ", runner))

  # ---- 5) Locate Python from virtual environment --------------------------
  shiny::incProgress(0.05, detail = "Locating Python")
  
  # Get the virtual environment path
  venv_path <- file.path(rappdirs::user_data_dir("ASUbuildR"), "asu-cpsat-venv")
  
  # Find the Python executable in the venv
  if (.Platform$OS.type == "windows") {
    pybin <- file.path(venv_path, "Scripts", "python.exe")
  } else {
    pybin <- file.path(venv_path, "bin", "python")
  }
  
  # Fallback to system Python if venv not found
  if (!file.exists(pybin)) {
    pybin <- Sys.which("python")
    if (pybin == "") pybin <- Sys.which("python3")
  }
  
  if (!nzchar(pybin) || !file.exists(pybin)) {
    shiny::showModal(shiny::modalDialog(
      title="Python not found",
      "Could not find the virtual environment or python executable.",
      easyClose=TRUE
    ))
    return(invisible(NULL))
  }
  append_cpsat_log(paste0("[run] Using Python: ", pybin))


  # ---- 6) Launch and STREAM output (processx::process) -----------------
  shiny::incProgress(0.35, detail = "Solving (streaming logs)…")
  env_map <- c(
    PYTHONUNBUFFERED = "1",
    OMP_NUM_THREADS  = "1",
    MKL_NUM_THREADS  = "1",
    OPENBLAS_NUM_THREADS = "1"
  )
  px <- processx::process$new(
    command = pybin,
    args    = c(runner),
    stdout  = "|",
    stderr  = "|",
    windows_hide_window = TRUE,
    env     = env_map
  )
  cpsat_solver_proc(px)
  append_cpsat_log(sprintf("[run] Python started (pid=%s). Streaming…", px$get_pid()))

  # Persistent observer to stream logs and finalize UI when done
  if (!is.null(session$userData$cpsatObs)) {
    try(session$userData$cpsatObs$destroy(), silent = TRUE)
  }
  tmr <- shiny::reactiveTimer(300)
  session$userData$cpsatObs <- shiny::observe({
    tmr()
    px <- cpsat_solver_proc()
    shiny::req(!is.null(px))

    # pull incremental lines
    out <- try(px$read_output_lines(), silent = TRUE)
    err <- try(px$read_error_lines(),  silent = TRUE)
    if (!inherits(out,"try-error") && length(out)) append_cpsat_log(paste(out, collapse="\n"))
    if (!inherits(err,"try-error") && length(err)) append_cpsat_log(paste(err, collapse="\n"))

    if (!px$is_alive()) {
      # drain remaining
      out_all <- try(px$read_all_output_lines(), silent = TRUE)
      err_all <- try(px$read_all_error_lines(),  silent = TRUE)
      if (!inherits(out_all,"try-error") && length(out_all)) append_cpsat_log(paste(out_all, collapse="\n"))
      if (!inherits(err_all,"try-error") && length(err_all)) append_cpsat_log(paste(err_all, collapse="\n"))

      status <- px$get_exit_status()
      append_cpsat_log(paste0("[run] Exit status: ", status))
      session$userData$cpsatObs$destroy()

      # ---- 7) Load results -> update map/reactives ---------------------
      if (identical(status, 0L) && file.exists(cpsat_out_json())) {
        res <- jsonlite::fromJSON(cpsat_out_json())
        if (!is.null(res$asu_id) && length(res$asu_id) == nrow(merged_df)) {
          asu_id <- as.integer(res$asu_id)
          final_sf <- merged_sf |>
            dplyr::mutate(asunum = ifelse(asu_id < 0L, 0L, as.integer(asu_id)))

          # update your existing reactives
          full_data(final_sf)
          full_data_reset(final_sf)
          asu_summary(
            final_sf |>
              sf::st_drop_geometry() |>
              dplyr::filter(asunum > 0) |>
              dplyr::group_by(asunum) |>
              dplyr::summarise(
                Tracts              = dplyr::n(),
                Population          = sum(tract_pop_cur,   na.rm = TRUE),
                `Labor Force`       = sum(tract_ASU_clf,   na.rm = TRUE),
                Unemployment        = sum(tract_ASU_unemp, na.rm = TRUE),
                `Unemployment Rate` = round(Unemployment/`Labor Force`*100, 5),
                .groups = "drop"
              )
          )
          map_geom({
            final_sf |>
              sf::st_make_valid() |>
              sf::st_zm(what = "ZM", drop = TRUE) |>
              dplyr::filter(!sf::st_is_empty(geometry)) |>
              dplyr::mutate(geom_type = sf::st_geometry_type(geometry)) |>
              dplyr::filter(geom_type %in% c("POLYGON","MULTIPOLYGON")) |>
              dplyr::select(-geom_type)
          })
          output$asu <- shiny::renderTable(asu_summary(), digits = 3)
          append_cpsat_log("[run] Solver finished OK; map/table updated.")
          # (Re)draw your map via your existing renderMaplibre code
          # (your existing renderMaplibre('initial_map') will pick up updated reactives)
        } else {
          append_cpsat_log("[run][warn] Output JSON invalid or length mismatch.")
        }
      } else {
        append_cpsat_log("[run][error] Solver failed or out.json missing.")
      }
    }
  })
})

})

shiny::observeEvent(input$th_combine, {
  shiny::req(th_state())
  shiny::withProgress(message = "Combining ASUs…", value = 0, {
    st <- tract_hunter_combine_groups(th_state())
  })
  th_state(st)
  res <- tract_hunter_finalize(st)
  full_data(res$full_data  )   ; full_data_reset(res$full_data_reset)
  asu_data(res$asu_data    )   ; asu_tracts(res$asu_tracts)
  asu_summary(res$asu_summary) ; map_geom(prep_map_data(res$full_data))
  output$asu <- shiny::renderTable( asu_summary(),digits = 3 )
  mapgl::maplibre_proxy("initial_map") |> mapgl::clear_layer("basemap")
  output$initial_map <- mapgl::renderMaplibre({
    shiny::req(map_geom())
    map_data <- map_geom()
    if (nrow(map_data) == 0) {
      return(
        mapgl::maplibre(style = mapgl::carto_style("positron")) |>
        mapgl::add_control("No valid polygon geometry to display.", "top-left")
      )
    }
    map_data <- map_data |>
      dplyr::mutate(asunum = dplyr::na_if(asunum, 0L))
    n_asu <- max(map_data$asunum, na.rm = TRUE)
    n_asu <- ifelse(is.finite(n_asu), n_asu, 0L)
    


    pal <- palette_logic(n_asu)
    mapgl::maplibre(style = mapgl::carto_style("positron")) |>
      mapgl::fit_bounds(map_data, animate = FALSE) |>
      mapgl::add_fill_layer(
        id                 = "basemap",
        source             = map_data,
        fill_color         = pal$fill,
        fill_opacity       = 0.5,
        fill_outline_color = "black"
      )
  })
})

#-------Total Unemployment Box --------------------------------
total_unemp <- shiny::reactive({
  shiny::req(full_data())                                  # wait until available
  full_data() |>
    dplyr::filter(asunum > 0) |>
    dplyr::summarise(unemp = sum(tract_ASU_unemp, na.rm = TRUE)) |>
    dplyr::pull(unemp)
})

output$total_unemp <- shiny::renderUI({
  shiny::HTML(
    paste0("<strong>Total Unemployment in ASUs:</strong> ",
           scales::comma(total_unemp()))
  )
})

output$total_unemp2 <- shiny::renderUI({
  shiny::HTML(
    paste0("<strong>Total Unemployment in ASUs:</strong> ",
           scales::comma(total_unemp()))
  )
})
```

## Solver Log {data-width="400"}

```{r}
# Show the log only when CP-SAT is selected
shiny::conditionalPanel(
  condition = "input.asu_algo === 'cpsat'",
  shiny::wellPanel(
    style = "height: 100vh; overflow-y: auto; background-color: #ffffff; font-family: monospace; font-size: 12px; padding: 10px;",
    shiny::verbatimTextOutput("cpsat_log_tail", placeholder = TRUE)
  )
)

# Show a placeholder when CP-SAT is not selected
shiny::conditionalPanel(
  condition = "input.asu_algo !== 'cpsat'",
  shiny::div(
    style = "padding: 20px; color: #666;",
    shiny::HTML("CP-SAT solver log will appear here when the CP-SAT algorithm is selected and running.")
  )
)
```

## Map {data-width="400"}
```{r}
mapgl::maplibreOutput("initial_map", height = "100vh")
```


# Modify ASU Selections

## Controls {data-width="150" style="height: 100vh; overflow-y: auto; padding-right: 10px;"}

These tools allow you to select, inspect, and change ASU designations for individual Census tracts.  *Selected* Census tracts will be outlined in red, and are the tracts updated when you change the ASU number.  You may also click on the map to select or unselect individual tracts. An ASU value of 0 means the tract is not included in any ASU.

```{r}
#-------Total Unemployment Box --------------------------------
shiny::htmlOutput("total_unemp2")
shiny::renderUI(shiny::HTML("<hr>"))

# Select an ASU
asu_selection_ui <- shiny::reactive({
  shiny::selectInput("select_asunum", "Select ASU Number:",
              choices = c("None", asu_choices()),
              selected = "None")
})
shiny::renderUI(asu_selection_ui())
shiny::renderUI(shiny::HTML("<hr>"))

# Change ASU
shiny::numericInput("new_asu", "Change ASU Value:", value = 0, min = 0)
shiny::actionButton("update", "Update Selected Tracts")
shiny::renderUI(shiny::HTML("<hr>"))

# Clear Selected Tracts
shiny::actionButton("clear", "Clear Selected Tracts")
shiny::renderUI(shiny::HTML("<hr>"))

# Show Data for Selection
shiny::actionButton("preview", "Show Data for Selected Tracts")
asu_choices <- shiny::reactive({
  shiny::req(full_data())                     # only run after full_data exists
  full_data() |> dplyr::pull(asunum) |> unique() |> sort()
})

shiny::renderUI(shiny::HTML("<hr>"))

# Show Lowest UR Tracts in Selection
shiny::selectInput("unemployment_filter", 
             "Highlight selected tracts with:",
             choices = list("Low unemployment" = "low", 
                           "High unemployment" = "high"),
             selected = "low")
shiny::numericInput("percentile", "Percentile Threshold:", value = 5, min = 1, max = 100, step = 1)
shiny::actionButton("filter_percentile", "Highlight Tracts")
shiny::actionButton("clear_percentile", "Clear Highlights")
shiny::renderUI(shiny::HTML("<hr>"))

# Single GROID Selection
shiny::textInput("manual_geoid", "Enter a GEOID:", placeholder = "32031990000")
shiny::actionButton("select_geoid", "Select a Single Tract")
shiny::renderUI(shiny::HTML("<hr>"))

# Reset to Initial Load
shiny::actionButton("reset", "Reset to Initial Data")
```

## Output {data-width="850"}

```{r}
mapgl::maplibreOutput("edit_map", height = "90vh")

shiny::tableOutput("selection_data")

shiny::tableOutput("selection_summary")

output$edit_map <- mapgl::renderMaplibre({

  shiny::req(map_geom())

  number_asus <- max(map_geom()$asunum)
  number_categories <- min(c(number_asus, 8))
  asu_per_category <- number_asus/number_categories
  
  # Create breaks for ASU categories, excluding 0
  if (number_categories == 1) {
    # Single ASU: just need one break at 1
    asu_breaks <- 1
    actual_categories <- 1
    brewer_pal <- "#7FC97F"  # Single color
  } else {
    # Multiple ASUs: create breaks from 1 to max, evenly spaced
    asu_breaks <- seq(from = 1, to = number_asus, length.out = number_categories)
    actual_categories <- max(3, number_categories)  # Ensure minimum of 3 for brewer.pal
    full_brewer_pal <- RColorBrewer::brewer.pal(actual_categories, "Accent")
    brewer_pal <- full_brewer_pal[1:number_categories]  # Take only what we need
  }

  mapgl::maplibre(style = mapgl::carto_style("positron")) |>
    mapgl::fit_bounds(map_geom(), animate = FALSE) |>
    mapgl::add_fill_layer(
      id = "basemap",
      source = map_geom(),
      fill_color = mapgl::step_expr(
        column = "asunum",
        base = "#E0E0E0",  # Grey for asunum == 0 (and anything < first break)
        stops = brewer_pal,
        values = asu_breaks,
        na_color = "#E0E0E0"
      ),
      fill_opacity = 0.5,
      fill_outline_color = "black",
      tooltip = mapgl::concat(
        "<strong>ASU Number: </strong>",mapgl::get_column("asunum"), "<br>",
        "<strong>Tract GEOID: </strong>",mapgl::get_column("GEOID"),"<br>",
        "<strong>Tract Population: </strong>",mapgl::number_format(mapgl::get_column("tract_pop_cur"), style = "decimal", maximum_fraction_digits = 0),"<br>",
                "<strong>Tract Labor Force: </strong>",mapgl::number_format(mapgl::get_column("tract_ASU_clf"), style = "decimal", maximum_fraction_digits = 0),"<br>",
        "<strong>Tract Unemployment Rate: </strong>",mapgl::number_format(mapgl::get_column("tract_ASU_urate"), style = "decimal", maximum_fraction_digits = 2),"%<br>",
        "<strong>Tract Unemployment: </strong>",mapgl::number_format(mapgl::get_column("tract_ASU_unemp"), style = "decimal", maximum_fraction_digits = 0),"<br>")
    )
})

# Select or Unselect tracts on click
shiny::observeEvent(input$edit_map_feature_click, {
  click <- input$edit_map_feature_click
  current_selection <- selected_tracts()
  
  # Extract the GEOID from the clicked feature properties
  clicked_geoid <- click$properties$GEOID
  
  # Check if clicked_geoid is not NULL and not empty
  if (is.null(clicked_geoid) || length(clicked_geoid) == 0 || is.na(clicked_geoid)) {
    return()  # Exit early if no valid GEOID
  }
  
  # Add or remove the selected tract
  if (clicked_geoid %in% current_selection) {
    current_selection <- setdiff(current_selection, clicked_geoid)
  } else {
    current_selection <- c(current_selection, clicked_geoid)
  }
  
  selected_tracts(current_selection)
  
  # Update the map highlighting
  if (length(current_selection) > 0) {
    selected_data <- subset(map_geom(), GEOID %in% selected_tracts())
    
    mapgl::maplibre_proxy("edit_map") |>
      mapgl::clear_layer("selected") |>
      mapgl::add_line_layer(
        id = "selected",
        source = selected_data,
        line_color = "red",
        line_width = 3,
        line_opacity = 1
      )
  } else {
    # Clear the selection layer if no tracts are selected
    mapgl::maplibre_proxy("edit_map") |>
      mapgl::clear_layer("selected")
  }
  
  # Update the selection table
  output$selection_table <- shiny::renderTable({
    selected_tracts()
  }, digits = 3)
})

# Clear Selected Tracts on Button Click
shiny::observeEvent(input$clear, {
  
  selected_tracts(NULL)
  
  # Update the map highlighting
    mapgl::maplibre_proxy("edit_map") |>
      mapgl::clear_layer("selected")
    return()
})

# Select tracts in an ASU from dropdown
shiny::observeEvent(input$select_asunum, {
  shiny::req(map_geom())
  
  # Skip if "None" is selected
  if (input$select_asunum == "None") {
    selected_tracts(NULL)
    mapgl::maplibre_proxy("edit_map") |>
      mapgl::clear_layer("selected")
    return()
  }
  
  # Get all tracts with the selected ASU number
  selected_tract_ids <- map_geom() |>
    dplyr::filter(asunum == as.numeric(input$select_asunum)) |>
    dplyr::pull(GEOID)
  
  # Update the selected_tracts reactive value
  selected_tracts(selected_tract_ids)
  
  # Get the filtered data for selected tracts
  selected_data <- subset(map_geom(), GEOID %in% selected_tract_ids)
  
  # Highlight the selected tracts on the map using maplibre proxy
  mapgl::maplibre_proxy("edit_map") |>
    mapgl::clear_layer("selected") |>
    mapgl::add_line_layer(
      id = "selected",
      source = selected_data,
      line_color = "red",
      line_width = 3,
      line_opacity = 1
    ) |> 
    mapgl::fit_bounds(selected_data, animate = TRUE)
})

# Select a single tract given a GEOID
shiny::observeEvent(input$select_geoid, {
  shiny::req(map_geom())

  # Get the selected tract's data
  selected_tract <- map_geom() |>
    dplyr::filter(GEOID == input$manual_geoid)
  
  # If the tract exists, highlight it and fit bounds
  if (nrow(selected_tract) > 0) {
    # Highlight the selected tract on the map using maplibre proxy
    mapgl::maplibre_proxy("edit_map") |>
      mapgl::clear_layer("selected") |>
      mapgl::add_line_layer(
        id = "selected",
        source = selected_tract,
        line_color = "red",
        line_width = 3,
        line_opacity = 1
      ) |>
      mapgl::fit_bounds(selected_tract, animate = TRUE)
    
    # Update the selected_tracts reactive value
    selected_tracts(selected_tract$GEOID)
  }
})

# Create a reactive expression that handles the filtering logic
filtered_tracts <- shiny::reactive({
  shiny::req(input$percentile, input$unemployment_filter, map_geom(), selected_tracts())

  potential_lighlights <- map_geom() |>
    dplyr::filter(GEOID %in% selected_tracts(),
           tract_pop_cur > 0)
  
  if (input$unemployment_filter == "low") {
    
    threshold <- stats::quantile(potential_lighlights$tract_ASU_urate, input$percentile/100)
    
    filtered_selected <- potential_lighlights |>
      dplyr::filter(tract_ASU_urate <= threshold,
             tract_ASU_urate > 0) |>
      dplyr::pull(GEOID)
  } else {
    
    threshold <- stats::quantile(potential_lighlights$tract_ASU_urate, 1-(input$percentile/100))
    
    filtered_selected <- potential_lighlights |>
      dplyr::filter(tract_ASU_urate >= threshold,
             tract_ASU_urate > 0) |>
      dplyr::pull(GEOID)
  }
  
  return(filtered_selected)
})

# Single observer that responds to changes in either input
shiny::observeEvent(list(input$filter_percentile, input$unemployment_filter), {
  
  filtered_selected <- filtered_tracts()
  highlighted_tracts(filtered_selected)
  
  filtered_data <- subset(map_geom(), GEOID %in% filtered_selected)
  
  mapgl::maplibre_proxy("edit_map") |>
    mapgl::clear_layer("highlighted") |>
    mapgl::add_fill_layer(
      id = "highlighted",
      source = filtered_data,
      fill_color = "black",
      fill_opacity = 0.8
    )
})

# Clear highlights with button click or when changing ASU selection
shiny::observeEvent(list(input$clear_percentile, input$select_asunum), {
  
  mapgl::maplibre_proxy("edit_map") |>
    mapgl::clear_layer("highlighted")
  
})

# Calculate and display a table of data for selected tracts
shiny::observeEvent(input$preview, {
  shiny::req(selected_tracts())

  replacement_data <- full_data() |>
    sf::st_drop_geometry() |>
    subset(GEOID %in% selected_tracts())

  edit_table(replacement_data)

  edit_table() |>
    dplyr::ungroup() |>
    dplyr::summarize(
      tracts = dplyr::n(),
      population = sum(tract_pop_cur, na.rm = TRUE),
      lf = sum(tract_ASU_clf, na.rm = TRUE),
      unemp = sum(tract_ASU_unemp, na.rm = TRUE),
      ur = round(unemp/lf*100, 5)
    ) |>
    edit_summary()

  # Show Preview of Selected Tracts
  output$selection_summary <- shiny::renderTable({
    edit_summary()
  })
})

# Update selected tracts to new ASU number.
shiny::observeEvent(input$update, {
  shiny::req(selected_tracts(), full_data())
  
  # Update the full_data reactive value
  updated_data <- full_data() |>
    dplyr::filter(GEOID %in% selected_tracts()) |>
    dplyr::mutate(asunum = as.numeric(input$new_asu)) |>
    rbind(
      full_data() |>
        dplyr::filter(!(GEOID %in% selected_tracts()))
    )
  
  # Update the reactive value
  full_data(updated_data)
  map_geom(prep_map_data(updated_data))
  
  # Clear selected tracts
  selected_tracts(NULL)
  
  # Update map to remove highlight on selected tracts
  mapgl::maplibre_proxy("edit_map") |>
    mapgl::clear_layer("selected")
})

# Reset data to initial data load from Excel input
shiny::observeEvent(input$reset, {
  shiny::req(full_data_reset(), full_data())
  
  # Reset the full_data reactive value
  full_data(full_data_reset())
  map_geom(prep_map_data(full_data_reset()))
  
  # Clear selected tracts
  selected_tracts(NULL)
  
  # Update map to remove highlight on selected tracts
  mapgl::maplibre_proxy("edit_map") |>
    mapgl::clear_layer("selected")
})

# OPTIMIZATION 7: Periodic cleanup for long sessions
shiny::observe({
  shiny::invalidateLater(60000)  # Every minute
  if (exists("gc")) gc()  # Clean up memory
}) |> 
shiny::bindEvent(input$update, ignoreInit = TRUE)
```

# Save and Load Data

## Controls {data-width="150"}

These buttons allow you to save the map in progress so that you can load
it again in the future to continue your work.

First, choose a save directory. The default is your current working
directory. After loading data, you can go directly to the ASU
Modification tab to continue making edits.

```{r}
# Directory selection - Simple text input approach
shiny::textInput("save_dir_path", "Save Directory Path:", value = getwd(), width = "100%")
#shiny::actionButton("browse_dir", "Browse for Directory") # non-functional
shiny::textOutput("current_save_dir")
shiny::textOutput("dir_status")
shiny::br()

shiny::actionButton("save_data", "Save Data")
shiny::fileInput("load_data", "Load Data", accept = c(".rds"))

# Reactive value to store the selected directory
save_directory <- shiny::reactiveVal(getwd())  # Default to current working directory

# Observer to handle directory path changes
shiny::observeEvent(input$save_dir_path, {
  if (!is.null(input$save_dir_path) && input$save_dir_path != "") {
    if (dir.exists(input$save_dir_path)) {
      save_directory(input$save_dir_path)
    }
  }
})

# # Alternative browse button (opens file dialog for directory selection)
# shiny::observeEvent(input$browse_dir, {
#   # This will work in RStudio or desktop R
#   if (interactive()) {
#     selected_dir <- tryCatch({
#       utils::choose.dir(default = save_directory(), caption = "Select Save Directory")
#     }, error = function(e) {
#       # For non-Windows systems, use tcltk
#       tryCatch({
#         tcltk::tk_choose.dir(default = save_directory(), caption = "Select Save Directory")
#       }, error = function(e2) {
#         NULL
#       })
#     })
#     
#     if (!is.null(selected_dir) && selected_dir != "") {
#       shiny::updateTextInput(session, "save_dir_path", value = selected_dir)
#       save_directory(selected_dir)
#     }
#   } else {
#     # In web-deployed apps, show instruction
#     shiny::showModal(shiny::modalDialog(
#       title = "Directory Selection",
#       "In web-deployed apps, please manually enter the directory path in the text field above.",
#       easyClose = TRUE
#     ))
#   }
# })

# Display current save directory
output$current_save_dir <- shiny::renderText({
  paste("Current save directory: ", save_directory())
})

# Display directory status
output$dir_status <- shiny::renderText({
  if (dir.exists(save_directory())) {
    "✓ Directory exists and is accessible"
  } else {
    "⚠ Directory does not exist - it will be created when saving"
  }
})

# Observer for saving the data
shiny::observeEvent(input$save_data, {
  shiny::req(full_data())
  
  # Use the selected directory
  save_path <- file.path(save_directory(), "saved_data.rds")
  
  # Check if directory exists, create if it doesn't
  if (!dir.exists(save_directory())) {
    dir.create(save_directory(), recursive = TRUE)
  }
  
  # Save the full_data object to an RDS file
  tryCatch({
    saveRDS(full_data(), save_path)
    
    # Provide feedback to the user
    shiny::showModal(shiny::modalDialog(
      title = "Data Saved",
      paste("Your data has been saved to:", save_path),
      easyClose = TRUE
    ))
  }, error = function(e) {
    shiny::showModal(shiny::modalDialog(
      title = "Error Saving Data",
      paste("Failed to save data:", e$message),
      easyClose = TRUE
    ))
  })
})

# Observer for loading the data
shiny::observeEvent(input$load_data, {
  shiny::req(input$load_data)
  
  # Read the RDS file into a data frame
  loaded_data <- tryCatch({
    readRDS(input$load_data$datapath)
  }, error = function(e) {
    shiny::showModal(shiny::modalDialog(
      title = "Error Loading Data",
      "Failed to load the data. Please check the file format.",
      easyClose = TRUE
    ))
    return(NULL)
  })
  
  # If loaded_data is NULL (failed to load), exit the observer
  shiny::req(!is.null(loaded_data))
  
  # Ensure the loaded data is an sf object
  if (!inherits(loaded_data, "sf")) {
    shiny::showModal(shiny::modalDialog(
      title = "Error Loading Data",
      "The loaded data is not a valid sf object.",
      easyClose = TRUE
    ))
    return(NULL)
  }
  
  # Update full_data with the loaded data
  full_data(loaded_data)
  map_geom(prep_map_data(loaded_data))
  
  # Provide feedback to the user
  shiny::showModal(shiny::modalDialog(
    title = "Data Loaded",
    "Your data has been successfully loaded.",
    easyClose = TRUE
  ))
  
  # Recreate the color scheme logic (same as in renderMaplibre)
  number_asus <- max(map_geom()$asunum)
  number_categories <- min(c(number_asus, 8))
  asu_per_category <- number_asus/number_categories
  
  # Create breaks for ASU categories, excluding 0
  if (number_categories == 1) {
    # Single ASU: just need one break at 1
    asu_breaks <- 1
    actual_categories <- 1
    brewer_pal <- "#7FC97F"  # Single color
  } else {
    # Multiple ASUs: create breaks from 1 to max, evenly spaced
    asu_breaks <- seq(from = 1, to = number_asus, length.out = number_categories)
    actual_categories <- max(3, number_categories)  # Ensure minimum of 3 for brewer.pal
    full_brewer_pal <- RColorBrewer::brewer.pal(actual_categories, "Accent")
    brewer_pal <- full_brewer_pal[1:number_categories]  # Take only what we need
  }
  
  # Update the map using maplibre_proxy
  mapgl::maplibre_proxy("edit_map") |>
    mapgl::clear_layer("basemap") |>
    mapgl::add_fill_layer(
      id = "basemap",
      source = map_geom(),
      fill_color = mapgl::step_expr(
        column = "asunum",
        base = "#E0E0E0",  # Grey for asunum == 0 (and anything < first break)
        stops = brewer_pal,
        values = asu_breaks,
        na_color = "#E0E0E0"
      ),
      fill_opacity = 0.5,
      fill_outline_color = "black",
      tooltip = mapgl::concat(
        "<strong>ASU Number: </strong>", mapgl::get_column("asunum"), "<br>",
        "<strong>Tract GEOID: </strong>", mapgl::get_column("GEOID"), "<br>",
        "<strong>Tract Unemployment Rate: </strong>", mapgl::number_format(mapgl::get_column("tract_ASU_urate"), style = "decimal", maximum_fraction_digits = 2), "%<br>",
        "<strong>Tract Unemployment: </strong>", mapgl::number_format(mapgl::get_column("tract_ASU_unemp"), style = "decimal", maximum_fraction_digits = 0), "<br>"
      )
    ) |>
    mapgl::fit_bounds(map_geom(), animate = TRUE)
})
```

## Output {data-width="850"}

```{r}
# Empty output section
```

# ASU Review and Finalization

## Controls {data-width="150"}

This screen will allow you to review your selected ASUs. It uses a
threshold of 6.45% unemployment and a population of 10,000, but these
numbers can be modified in case they change in the future.

*Generate ASU Summary* will show a table of all ASUs, and whether they
pass or fail the ASU definitions for unemployment and population. Please
pay attention to these measures - an unemployment rate of 6.449% will
display as 6.45%, but will fail the validation.

Note, you *may* go back and forth between the selection and review
screens.

When ready to create an output file, the *Generate LSS .txt File* button
will create a formatted batch file for upload to LSS.

```{r}
shiny::numericInput("asu_ur", "ASU Unemployment Rate Threshold:", value = 6.45, min = 0)

shiny::numericInput("asu_pop", "ASU Population Threshold:", value = 10000, min = 0)

shiny::actionButton("run_asu_summary", "Generate ASU Summary")
shiny::renderUI(shiny::HTML("<hr>"))

shiny::textOutput("current_save_dir")
shiny::renderUI(shiny::HTML("<hr>"))

shiny::actionButton("lss_txt", "Generate LSS .txt File")
shiny::renderUI(shiny::HTML("<hr>"))

shiny::actionButton("review_txt", "Create Summary CSV")
```

## Output {data-width="850"}

```{r}
shiny::tableOutput("asu_review")

summarized_asu <- shiny::reactiveVal(NULL)

shiny::observeEvent(input$run_asu_summary, {
  
  shiny::req(full_data())
  
  summary_table <- full_data() |>
    sf::st_drop_geometry() |>
    dplyr::group_by(asunum) |>
    dplyr::filter(asunum > 0.5) |>
    dplyr::summarize(
      Tracts = dplyr::n(),
      Population = sum(tract_pop_cur, na.rm = TRUE),
      `Labor Force` = sum(tract_ASU_clf, na.rm = TRUE),
      Unemployment = sum(tract_ASU_unemp, na.rm = TRUE),
      `Unemployment Rate` = round(Unemployment/`Labor Force`*100, 5)
    ) |>
    dplyr::ungroup() |>
    dplyr::mutate(
      ur_qualified = dplyr::if_else(`Unemployment Rate` >= input$asu_ur, TRUE, FALSE),
      pop_qualified = dplyr::if_else(Population >= input$asu_pop, TRUE, FALSE),
      asu_qualified = ur_qualified & pop_qualified
    )
  
  summarized_asu(summary_table)
})

output$asu_review <- shiny::renderTable({
  summarized_asu()
})

shiny::observeEvent(input$lss_txt, {
  
  shiny::req(full_data())

  # Function to generate text content
  generate_txt <- function() {
    df <- full_data() |>
      sf::st_drop_geometry() |>
      dplyr::select(GEOID, asunum) |>
      dplyr::filter(asunum > 0) |>
      dplyr::mutate(asunum = as.integer(asunum),
             GEOID = paste0("14000US", GEOID),
             asunum = paste0("SU", state(), sprintf("%04d", asunum)),
             GEOID = paste(asunum, GEOID, sep = " + ")) |> 
      dplyr::arrange(asunum, GEOID) |>
      dplyr::select(-asunum)

    txt_content <- utils::capture.output(utils::write.table(df, quote=FALSE, row.names=FALSE, col.names = FALSE))
    txt_content <- paste(txt_content, collapse="\n")
    return(txt_content)
  }

  # Get the current save directory from the reactive value
  current_dir <- save_directory()
  
  # Validate directory path
  if (is.null(current_dir) || current_dir == "") {
    shiny::showModal(shiny::modalDialog(
      title = "No Directory Selected",
      "Please select a save directory first in the Save and Load Data tab.",
      easyClose = TRUE
    ))
    return()
  }

  # Create the content
  txt_content <- generate_txt()

  # Use the selected save directory
  filePath <- file.path(current_dir, "lss_batch_file.txt")
  
  # Ensure directory exists
  if (!dir.exists(current_dir)) {
    tryCatch({
      dir.create(current_dir, recursive = TRUE)
    }, error = function(e) {
      shiny::showModal(shiny::modalDialog(
        title = "Directory Error",
        paste("Cannot create directory:", current_dir, "\nError:", e$message),
        easyClose = TRUE
      ))
      return()
    })
  }
  
  tryCatch({
    # Write the file
    writeLines(txt_content, filePath)
    
    # Show success message with file location
    shiny::showModal(shiny::modalDialog(
      title = "File Created Successfully",
      shiny::HTML(paste0(
        "<strong>LSS batch file has been saved to:</strong><br>",
        "<code>", filePath, "</code>"
      )),
      easyClose = TRUE
    ))
    
  }, error = function(e) {
    shiny::showModal(shiny::modalDialog(
      title = "Error Creating File",
      paste("Failed to create LSS file:", e$message),
      easyClose = TRUE
    ))
  })
})

shiny::observeEvent(input$review_txt, {

  shiny::req(full_data())

  # Function to generate CSV content
  generate_csv <- function() {
    df <- full_data() |>
      sf::st_drop_geometry() |>
      dplyr::arrange(asunum, GEOID)
    
    return(df)
  }
  
  # Get the current save directory from the reactive value
  current_dir <- save_directory()
  
  # Validate directory path
  if (is.null(current_dir) || current_dir == "") {
    shiny::showModal(shiny::modalDialog(
      title = "No Directory Selected",
      "Please select a save directory first in the Save and Load Data tab.",
      easyClose = TRUE
    ))
    return()
  }

  # Create the content
  df <- generate_csv()

  # Use the selected save directory
  filePath <- file.path(current_dir, "ASU_Review_File.csv")
  
  # Ensure directory exists
  if (!dir.exists(current_dir)) {
    tryCatch({
      dir.create(current_dir, recursive = TRUE)
    }, error = function(e) {
      shiny::showModal(shiny::modalDialog(
        title = "Directory Error",
        paste("Cannot create directory:", current_dir, "\nError:", e$message),
        easyClose = TRUE
      ))
      return()
    })
  }
  
  tryCatch({
    # Write the CSV file
    utils::write.csv(df, filePath, row.names = FALSE)
    
    # Show success message with file location
    shiny::showModal(shiny::modalDialog(
      title = "File Created Successfully",
      shiny::HTML(paste0(
        "<strong>ASU Review CSV has been saved to:</strong><br>",
        "<code>", filePath, "</code>"
      )),
      easyClose = TRUE
    ))
    
  }, error = function(e) {
    shiny::showModal(shiny::modalDialog(
      title = "Error Creating File",
      paste("Failed to create CSV file:", e$message),
      easyClose = TRUE
    ))
  })
})

####################
## Future Development

# Export Excel Worksheet with tract details and selections.
# Allow "Save" of data with txt/Excel files so single session is not required.
# Better table formatting.
# highlight high unemployment tracts in non-included areas.
# Check for contiguity of selected ASUs after manual edits.
# Export high-resolution images of ASUs for review.
# Use reactlog package to monitor reactive interactions in the code for cleanup. https://mastering-shiny.org/reactive-graph.html
```

# How to Use ASUbuildR

**About ASUloadR**

ASUloadR is an application built in R using Shiny and Flexdashboard to
create a point-and-click environment to build Areas of Substantial
Unemployment (ASU). While this package does not replace the work of an
analyst in a state from working on the ASU process, it provides tools to
make that process more straightforward. It should be noted, the U.S. Bureau of Labor Statistics has several
options for designating ASUs. **ASUloadR** only uses the addition
method, building regions at the Census Tract level. Analysts may
discover that other alternatives work better for their state in a given
year.

The ASU creation logic in this program was created by a collaboration
between the states of Ohio and Nevada, with the Shiny app and Graphical
User Interface designed by Nevada’s Research & Analysis Bureau. The Github repository for this package can be found at <https://github.com/schmidtDETR/ASUbuildR>

**About the ASU Process**

The ASU process typically begins when the U.S. Bureau of Labor
Statistics distributes to each state a file providing the calculated
inputs for regions within the state from which ASUs must be designated.
This is provided as an Excel sheet with a filename like `ST_asuYY.xlsx`
where ST is the state abbreviation and YY is the year for which the ASU
is being designated. **ASUloadR** is currently designed to pull
information directly from this file, including identifying the state and
year for which data should be retrieved. Because this file is built using public information but using
preliminary LAUS data for June of the current year, archives of these
files are not publicly available but also do not contain confidential
information. Future versions of ASUloadR may build these input files
directly, but currently the state-specific input file is required.

ASUs are required to meet three elements to be considered. First, the
region must be geographically contiguous (including corner-to-corner
intersections). Second, the region must have a population of at least
10,000. Third, the unemployment rate in the region must be at least
6.5%. The methodology in **BLSloadR** looks at each census tract with an
unemployment rate of at least 6.45%, then adds the adjacent tract with
the next-highest unemployment rate (or a labor force of 0), and
continues until the unemployment rate in the combined region is \<6.45%.
It then removes the last-added tract, designates the region as an ASU,
and continues with the next-highest remaining unused tract in the state.
It continues building regions until there are no remaining tracts with a
rate of at least 6.45%, then stops.

**Using ASUloadR**

The basic functionality of **ASUloadR** is simple. First, install the
package. Second, call the `launch_ASUloadR()` function. If you prefer,
you don’t even have to load the package into your library, just call it
directly with `ASUloadR::launch_ASUloadR()`. By default, this will
launch the **ASUloadR** Shiny app in your default browser window.

**Basic Navigation**

Within the app window, there are a series of tabs across the top. These
control the basic navigation within the app. The functionality of each
tab will be described in detail below.

-   Data Initialization: this is where you load the Excel file from BLS.

-   Load Initial ASU: here you use the data from BLS to generate an
    initial list of potential ASUs.

-   Modify ASU Selections: this is the primary window you will interact
    with. It allows for the manipulation and refinement of the data.

-   Save and Load Data: this allows you to save the current state of the
    modified data and maps to be loaded later. If you have already saved
    data, you can come straight here to load that map.

-   ASU Review and Finalization: this tab contains tools to review the
    summarized ASUs, to generate an output CSV file to review individual
    tracts, and to generate a batch TXT file that can be uploaded to
    BLS.

**Data Initialization**

To begin the ASU building process, click the `Browse` button on the left
side of the page. Once a file has been selected, an overview of the file
will appear on the right to confirm the file has successfully loaded.
You may review the contents of the columns to ensure that data appears
to be loaded correctly. This script assumes the columns are maintained
in a consistent order by BLS - changes to the structure of the file will
require updates to the structure of this code.

When review is complete, continue to the next tab - Load Initial ASU.

**Load Initial ASU**

There are two options available to the user at this stage.  The **Tract Hunter** is a process that will iteratively build ASU regions by seeding an initial map, then comparing potential targeted tracts to add or remove, with the goal of achieving the maximum level of unemployment within ASUs. Tract Hunter includes logic to only allow ASUs that meet the minimum 10,000 population threshold.

The original **Simple Snake** methodology starts from tracts with an unemployment rate of at least 6.45%, then sequentially adding the adjacent tract with the highest unemployment rate until the combined region is less than 6.45%. Because this starts from single tracts, it does not consider whether the combined population qualifies as an ASU.

If the state being loaded is a New England state, you will see an additional option to select the year to download.  Because the Census Bureau only maintains NECTA-based census tracts for 2021 and earlier, using the default settings may cause the app to crash if your Excel file uses these older GEOIDs.

To begin the ASU designation process, choose a methodology.  Then, click the
`Load Tracts and Initialize ASU` button. This will download the appropriate shapefiles from the Census and execute the tract-by-tract ASU building process. Small states may see this process run in under 20 seconds. The largest states may take up to 5 minutes. When the process is complete, the app will render a map to on the right side of the page. The number of colors on this map is limited to 8, so if more than 8 potential ASUs are identified, more than one ASU will use the same color.

If using the Tract Hunter, use the **Run Hunter** and **Combine Groups** buttons to allow the algorithm to attempt to improve the existing ASUs.

In addition, note that a table of the potential ASUs will appear below
the button. This will give the analyst a sense of how many tracts may be
worth merging into larger ASUs. In general, regions with 3 or fewer
tracts are unlikely to meet the population threshold to qualify as an
ASU.

To begin manually manipulating the data, proceed to the next tab, Modify ASU
Selections. Or, if the number of modifications is large or the state
takes a long time to run, skip ahead to perform an initial save of the
data on Save and Load Data.

**Modify ASU Selections**

This tab is where all edits to the ASU selections are made. A number of
tools are provided to aid in the optimization of the ASUs. In general,
*selected* tracts will be outlined in red on the map.

-   Hover over the map. Hovering the mouse over the map will display
    information about that tract useful to the selection process.

-   Click on the map. Clicking on the map will select, or unselect, a
    particular tract.

-   Select ASU Number: This dropdown allows you to select all the tracts
    in a particular ASU. If you select None, this will effectively clear
    all selected tracts.

-   Change ASU Value / Update Selected Tracts: This is how you change
    the pre-assigned ASU number. Enter the numeric value in the box
    under *Change ASU Value:* and then click the *Update Selected
    Tracts* to change the value. The numeric value remains in the box,
    providing a convenient way to keep changing tracts or groups of
    tracts to the same ASU. Further, changing the ASU number to 0 is how
    selected tracts are removed from any ASUs.

-   Show Data for Selected Tracts: This will generate a table below the
    map which has the aggregated ASU data for all selected tracts. This
    may help with determining whether it is efficient to add a tract or
    group of tracts to an existing ASU.

-   Percentile Threshold: This allows you to examine the tracts in your current selection with either high or low unemployment rates.  This is useful for identifying tracts outside of current ASUs that you may wish to include in an ASU or identifying tracts inside of current ASUs that you may with to drop.  Please choose whether you want to highlight Low or High unemployment tracts and enter a number in the Percentile Threshold box to highlight the top or bottom X% of tracts (X is the number you enter).  For example, if you have 200 tracts selected and choose 5 as your threshold and High unemployment, clicking the **Highlight Tracts** button will turn the color of the 10 tracts with the highest unemployment rates black.  Selecting **Clear Highlights** will clear all current highlighting.

-   Enter a GEOID / Select a Single Tract: This functionality is most
    useful when using the CSV output that this app generates on the
    **ASU Review and Finalization** tab. Given the 11-character GEOID,
    you can input that to highlight a single tract to examine where it
    fits. This can be helpful for fine-tuning - reviewing the
    highest-unemployment tracts not included in an ASU to ensure they
    cannot be connected in to improve the ASU.

-   Reset to Initial Data: This button will reset all changes you have
    made to the state of the map after the **Load Initial ASU** process.
    For when you’ve just broken everything and want to start over. Use
    with caution!

**Save and Load Data**

This tab contains some simple options to help save and load the current
state of the map. While Nevada had only 6 initial ASUs to review other
states may have over 100! This will save the background data of the app
as an RDS file, or load data from an RDS file.

To specify a directory other than your working directory, paste that
directory into the `Save Directory Path` box.

**ASU Review and Finalization**

This will typically be the last screen in the process. Here, you may
test the ASUs you have created against the required numeric thresholds
using `Generate ASU Summary` - this is most useful for validating edge
cases, when the calculated aggregate ASU rate is less than but rounds up
to 6.45. Because the criteria for an ASU is an unemployment rate of
6.5%, a rate of 6.449% will not qualify. The TRUE/FALSE outputs in the
table provide the most reliable test for whether the ASU will qualify.

Generate LSS .txt File and Create Summary CSV will both create files in
the directory specified in the **Save and Load Data** tab (or your
working directory). The LSS TXT file should be formatted to be able to
upload to LSS directly once the ASUs are completed. The Summary CSV file
provides a handy output of all selected tracts and a useful tool to
review the selections for high-unemployment tracts that were not
included.
